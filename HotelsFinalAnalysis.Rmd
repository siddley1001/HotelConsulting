---
title: "HotelsFinalAnalysis"
author: "Walker Burgin, Tara Ghorpadkar, David Snider, Sid Vanam"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
```


```{r,include=F}
library(tidyverse)
library(countrycode)
library(rvest)
library(dplyr)
library(tidyr)
library(xtable)
library(modelr)
library(broom)
library(class)
library(lubridate)
library(pracma)
library(class)
library(randomForest)


df = read_csv("hotel_booking.csv")
k_df = read_csv("k_df.csv")
rf_stats = read_csv("rf_stats.csv")
```

<center>

![Vila Vita Resort in Algarve, Portugal. Provided by The Leading Hotels of the World.](lw1306_82442005_720x450.jpg)

</center>

# Introduction

Our group used data describing hotel bookings from two hotels in Portugal to answer questions relevant to the travel industry. Our first goal was to predict room rates with confidence. Such a tool would be valuable for travel agencies, hotels, and customers. Although hotels can provide rates only for a finite number of months, a model that predicts future rates may enable travel agencies to book vacations further into the future. Using this model, travel agencies would better serve as a middleman by providing more utility to customers and hotels. Customers could have more booking options with greater price certainty, while hotels could increase ease of transaction. Hotels could also understand seasonal and cyclical consumer demand patterns earlier and thus prepare their budget accordingly.

Our second goal was to predict whether the customer would cancel their booking. In our dataset, about one-third (0.37) of bookings ended up getting canceled. Hotels that can accurately predict customer cancellation can proactively modify operations. Hotels could double book rooms that have high cancelation to try and still make a profit. Alternatively, predicting canceled books can help customers. For example, when asking if a customer wishes to join a waitlist, the hotel can inform them of the likelihood of cancellation or the probability of getting that room. 

# Data

```{r, include=F}
#data cleaning
cleaned1 = df %>% 
  filter(is_canceled == 0) %>% 
  dplyr::select(
    hotel,
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month,
    stays_in_week_nights, 
    stays_in_weekend_nights, 
    adr) %>% 
  mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% 
  arrange(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month) %>%
  dplyr::select(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month, 
    length_of_stay, 
    adr, 
    hotel) 
cleaned1$arrival_date_month = as.integer(
  factor(cleaned1$arrival_date_month, 
         levels = month.name))
cleaned1 = cleaned1 %>%
  unite("arrival_date", 
        c("arrival_date_year", 
          "arrival_date_month", 
          "arrival_date_day_of_month"), 
        sep = "/") %>% 
  filter(adr != 0.00)

city_hotels2 = cleaned1 %>% 
  filter(hotel == "City Hotel")
resort_hotels2 = cleaned1 %>%
  filter(hotel == "Resort Hotel")

# city_hotels2 = city_hotels2 %>% 
#   dplyr::select(
#     arrival_date_year, 
#     arrival_date_month, 
#     arrival_date_day_of_month, 
#     length_of_stay, 
#     adr) %>% 
#   unite("arrival_date", 
#         c("arrival_date_year", 
#           "arrival_date_month", 
#           "arrival_date_day_of_month"), 
#         sep = "/") %>% 
#   filter(adr != 0.00)

city_hotels2$arrival_date <- as.Date(city_hotels2$arrival_date)
city_hotels2 = city_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )
resort_hotels2$arrival_date <- as.Date(resort_hotels2$arrival_date)
resort_hotels2 = resort_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )

model_data_city = city_hotels2
start_date = as.Date("2015-07-01")
model_data_city$arrival_date <- as.numeric(
  difftime(model_data_city$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.city <- model_data_city$arrival_date

model_data_resort = resort_hotels2
model_data_resort$arrival_date <- as.numeric(
  difftime(model_data_resort$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.resort <- model_data_resort$arrival_date
```

The dataset contains 119,319 bookings for two hotels located in Portugal over about two years. There are 32 variables included in the data set; our research questions concerned a select few. **Our first question uses `"arrival_date"` to predict the variable `"avg_adr"`.** Our group combined the variables `"arrival_date_year"`, `"arrival_date_month"`, and `"arrival_date_day_of_month"` into the variable `"arrival_date"`, to record the client's date of arrival in elapsed days since July 1, 2015 (the earliest arrival date). For modeling, we converted `"arrival_date"` into a Date type, and used a function to obtain days elapsed from 07/01/2015.  We created the variable `"avg_adr"` using the variable `"adr"`. `"adr"` is the client's total transaction costs divided by their staying days. In creating `"avg_adr"`, we calculated the mean ADR value for one day for each hotel. After establishing these variables, one can easily observe the increasing oscillating relationship between `"avg_adr"` and `"arrival_date"`, which motivated our first question. 

```{r, echo=F, results="asis"}
#Table for Q1
q1table = model_data_city %>% 
  head(4) %>%
  mutate(arrival_date = as.integer(arrival_date)) %>%
  xtable(
    align=c("c","c","c"),
    type="html",
    caption = "Table 1: Example Data for Q1")
print(q1table, 
      "html", 
      caption.placement = "top",
      scalebox = 0.7,
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")

```

**Our second question predicts the variable `"is_canceled"`**, which has a value of 1 if the booking was canceled, and 0 otherwise. Analysis revealed that certain variables had a statistically significant relationship with is_canceled. The following are the variables we analyzed. `"hotel"` describes whether the observation was at the city hotel or the resort hotel. `"is_repeated_guest"` is a binary variable, valued at 1 if the guest has booked previously. `"lead_time"` describes the number of days between entrance into the booking system and the customer's arrival. `"previous_bookings_not_canceled"` describes the number of the client's previous bookings that were not canceled, while `"previous_cancellations"` describes those that were canceled.

```{r, results="asis", echo=F}
q2table = (df %>% select(
  is_canceled,
  hotel,
  is_repeated_guest,
  adr,
  lead_time,
  previous_bookings_not_canceled,
  previous_cancellations
  ) %>% 
  filter(adr!= 0))[3:7,] %>%
  mutate(
    is_canceled=as.integer(is_canceled),
    is_repeated_guest=as.integer(is_repeated_guest),
    lead_time=as.integer(lead_time),
    previous_bookings_not_canceled = as.integer(previous_bookings_not_canceled),
    previous_cancellations = as.integer(previous_cancellations)
  ) %>%
  xtable(
    align="cccccccc", 
    type="html",
    caption = "Table 2: Example Data for Q2"
    )
print(q2table,
      "html",
      caption.placement = "top",
      scalebox = 0.7,
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")
```

# Results

## Question 1: Can we predict future room rates with confidence?

```{r, echo=F, fig.align="center", fig.width=6, fig.height=6 }
xc <- cos(2*pi*model_data_city$arrival_date/365.25)
xs <- sin(2*pi*model_data_city$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_city)
model_data_city$pred1 <- predict(fit.lm, model_data_city)
model.func = function(day){
  return(
    fit.lm$coefficients[[1]] + fit.lm$coefficients[[2]]*cos(2*pi*day/365.25) + fit.lm$coefficients[[3]]*sin(2*pi*day/365.25) + fit.lm$coefficients[[4]]*day
  )
}
p1 <- ggplot() + 
  geom_point(data = model_data_city, aes(x = arrival_date, y = avg_adr)) + 
  geom_hline(aes(yintercept=0))
p1.trend = p1  + 
  geom_line(data = model_data_city, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_city = bind_rows(model_data_city, new)
model_data_city$pred <- model.func(model_data_city$arrival_date)

#Graph
p1.trend + 
  geom_line(data = model_data_city, 
            aes(x = arrival_date, 
                y = pred)) + geom_vline(xintercept = 365) + geom_vline(xintercept = 730) + geom_vline(xintercept = 1095) + xlab("Days elapsed since July 1, 2015") + ylab("Average Daily Rate") + ggtitle("City Hotel Predictions")
```

```{r, echo=F, fig.align="center", fig.width=6, fig.height=6}
xc <- cos(2*pi*model_data_resort$arrival_date/365.25)
xs <- sin(2*pi*model_data_resort$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_resort)
model_data_resort$pred1 <- predict(fit.lm, model_data_resort)
p2 <- ggplot() + geom_point(data =model_data_resort, aes(x = arrival_date, y = avg_adr)) + geom_hline(aes(yintercept=0))
p2.trend = p2  + 
  geom_line(data = model_data_resort, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_resort = bind_rows(model_data_resort, new)
model_data_resort$pred <- model.func(model_data_resort$arrival_date)

#Graph
p2.trend + 
  geom_line(data = model_data_resort, aes(x = arrival_date, y = pred)) + 
  geom_vline(xintercept = 792) + geom_vline(xintercept = 365) + geom_vline(xintercept = 730) + geom_vline(xintercept = 1095) + xlab("Days elapsed since July 1, 2015") + ylab("Average Daily Rate") + ggtitle("Resort Hotel Predictions")
```

```{r, echo=F, message=F, fig.align="center", fig.width=6, fig.height=6}
#Walker's
h <- read.csv("hotel_booking.csv")
h2 = h %>% 
  select(hotel, 
         arrival_date_month, 
         arrival_date_day_of_month, 
         arrival_date_year, 
         country,
         adr, 
         is_canceled) %>% 
  rename(tp = hotel, 
         ogn = country, 
         aM = arrival_date_month, 
         aD = arrival_date_day_of_month, 
         aY = arrival_date_year, 
         adr = adr)
month_levels <- c("January", "February", "March", "April", 
                  "May", "June", "July", "August", 
                  "September", "October", "November", "December")
repeat_levels <- c(0, 1)
h2$aM =  factor(h2$aM,levels = month_levels)
ct_h = h2 %>% 
  filter(tp == "City Hotel", is_canceled == 0) %>% 
  filter(ogn != "NULL")
rst_h = h2 %>% 
  filter(tp == "Resort Hotel", is_canceled == 0) %>% 
  filter(ogn != "NULL")
ct_h_freq = ct_h%>% 
  filter(adr != 0.00)%>% 
  group_by(ogn, aM) %>% 
  summarise(n = n()) %>% 
  mutate(frequency = n/sum(n))
rst_h_freq = rst_h %>% 
  filter(adr != 0.00)%>% 
  group_by(ogn, aM) %>% 
  summarise(n = n()) %>% 
  mutate(frequency = n/sum(n))
ct_h_adr = ct_h %>% 
  group_by(ogn, aM) %>% 
  arrange(ogn, aM) %>% 
  summarize_at(vars(adr),funs(mean(.,na.rm = TRUE) )) %>% 
  rename(amr = adr) 
rst_h_adr = rst_h %>% 
  group_by(ogn, aM) %>% 
  arrange(ogn, aM) %>% 
  summarize_at(vars(adr), funs(mean(., na.rm = TRUE) )) %>% 
  rename(amr = adr) 
ct_h_top = ct_h %>% 
  group_by(ogn) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
ct_h_join = inner_join(ct_h_adr, ct_h_top, by = "ogn")
rst_h_top = rst_h %>% 
  group_by(ogn) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
rst_h_join = inner_join(rst_h_adr, rst_h_top, by = "ogn")
ct_h_freq = ct_h_freq %>% 
  filter(n > 80, frequency < 0.6)

h2 = h %>% 
  filter(hotel == "City Hotel", is_canceled == 0) %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month,stays_in_week_nights, stays_in_weekend_nights, adr) %>% mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% arrange(arrival_date_year, arrival_date_month, arrival_date_day_of_month)

h2$arrival_date_month = as.integer(factor(h2$arrival_date_month, levels = month.name))

h2 = h2 %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month, length_of_stay, adr) %>% unite("arrival_date", c("arrival_date_year", "arrival_date_month", "arrival_date_day_of_month"), sep = "/") %>% filter(adr != 0.00)

h2$arrival_date <- as.Date(h2$arrival_date)
h2 = h2 %>% arrange(arrival_date)  %>% group_by(arrival_date) %>% summarise(avg_length_of_stay = mean(length_of_stay), avg_adr = mean(adr))

mod = h2
start_date = as.Date("2015-07-01")
mod$arrival_date <- as.numeric(difftime(mod$arrival_date, start_date, unit = "days"))
NumDays.city <- mod$arrival_date
xc <- cos(2*pi*NumDays.city/365.25)
xs <- sin(2*pi*NumDays.city/365.25)  
fit.lm <- lm(avg_adr ~ xc + xs + mod$arrival_date, data = mod)
model.func = function(day) {
  return(
    fit.lm$coefficients[[1]] + 
    fit.lm$coefficients[[2]]*cos(2*pi*day/365.25) + 
    fit.lm$coefficients[[3]]*sin(2*pi*day/365.25) + 
    fit.lm$coefficients[[4]]*day
  )
}
new = data.frame(arrival_date=793:1577)
mod = bind_rows(mod,new)
mod$pred <- model.func(mod$arrival_date)
mod$residual <- mod$avg_adr-mod$pred


resid <- remove_missing(mod,na.rm=TRUE,vars = names(mod))
resid$r2 <- resid$residual^2
RMSError <- sqrt(mean(resid$r2))
f_density<- function(x){
  (1+(x/1577))^2
}

#Graph
ggplot()+
  geom_errorbar(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred,
      ymax=mod$pred+(f_density(mod$arrival_date)*RMSError),
      ymin=mod$pred-(f_density(mod$arrival_date)*RMSError)),
    alpha=.025,
    color="red")+
  geom_point(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$avg_adr),
    size=1,
    color="red",
    alpha=.25)+
  xlab("Time Elapsed Since 1 July 2015 (days)")+
  ylab("Average Adr")+
  theme_classic()+
  ggtitle("Forecasted Average ADR")+
  geom_vline(xintercept = 793,linetype=1,alpha=.05)+
  geom_line(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred),
    color="purple",
    size=.5)+
  geom_smooth(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred+(2*f_density(mod$arrival_date)*RMSError)),
      xseq=793:1577,
      se=FALSE,
      color="red",
      alpha=.25,
      linetype=1,
      size=.5
    )+
  geom_smooth(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred-(2*f_density(mod$arrival_date)*RMSError)),
      xseq=793:1577,
      se=FALSE,
      color="red",
      alpha=.25,
      linetype=1,
    size=.5
    )+
  geom_vline(xintercept=365.25/2,color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(3/2),color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(5/2),color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(7/2),color="red",linetype=3,size=.5)

#Graph
ggplot()+theme_classic()+
  ggtitle("Accuracy of Predicted Curve")+
  ylab("Average ADR")+
  xlab("Arrival Date (Elapsed Time)")+
  geom_area(mapping=aes(x=resid$arrival_date,y=resid$residual),fill="red")+
  geom_hline(yintercept = RMSError,linetype=2)
```

Our prediction model is displayed in "Forecasted Average ADR", with confidence intervals defined by the RMSE of 13.31. Our second chart, "Accuracy of Predicted Curve", identifies which segments of the prediction model are less accurate than others at mapping the dataset.

## Question 2: Which model best predicts cancellation?

### How do significant variables correlate with cancellation?

To determine which variables we should use in our models, we started by identifying the variables that had a significant relationship with cancellation. Here are graphs showing the significant variables' relationship with cancellation: 

```{r, echo=F, figures-side, fig.show="hold", out.width="50%"}
leadgraph = df %>% 
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_lead_time = mean(lead_time)) %>% 
  ungroup() %>%
  rename(value=avg_lead_time)
leadgraph$key=rep("Lead Time", 2)

prevgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_canc = mean(previous_cancellations)) %>% 
  ungroup() %>%
  rename(value=avg_prev_canc)
prevgraph$key=rep("Previous Cancellations", 2)

prevuncancgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_uncanc = mean(previous_bookings_not_canceled)) %>% 
  ungroup() %>%
  rename(value=avg_prev_uncanc)
prevuncancgraph$key=rep("Previous Bookings Not Canceled", 2)

adrgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_adr = mean(adr)) %>% 
  ungroup() %>%
  rename(value=avg_adr)
adrgraph$key=rep("ADR", 2)

fullgraph = bind_rows(leadgraph, prevgraph, prevuncancgraph, adrgraph)

#Graph
ggplot(fullgraph, aes(x=`as.logical(is_canceled)`, y=value)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales = "free") + 
  xlab("Is Canceled?") + 
  ylab("Mean Value")
  
hotelgraph = df %>%
  group_by(hotel) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=hotel)
hotelgraph$key=rep("Hotel", 2)

repeatgraph = df %>%
  group_by(as.logical(is_repeated_guest)) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=`as.logical(is_repeated_guest)`)
repeatgraph$key=rep("Is Repeated Guest?", 2)
repeatgraph$value=as.character(repeatgraph$value)

fullgraph2 = bind_rows(hotelgraph, repeatgraph)

#Graph
ggplot(fullgraph2, aes(x=value, y=prop_canceled)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales="free") + 
  xlab("Value") + 
  ylab("Proportion Canceled")
```

Below are the P values for the above relationships. The P values for the first 4 variables were calculated using a T-test. The P values for the last 2 were calculated using a two proportion Z-test.

```{r, results="asis", echo=F}
pvals = c()

pvals = c(
  t.test(df$lead_time~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_cancellations~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_bookings_not_canceled~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$adr~as.logical(df$is_canceled))$p.value[[1]],
  (prop.test(x=hotelgraph$num_canceled, 
             n=hotelgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]],
  (prop.test(x=repeatgraph$num_canceled, 
             n=repeatgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]]
)
pvals=formatC(x=pvals, format="e", digits=2)

vars = c("Average Lead Time",
         "Average Previous Cancellations",
         "Average Previous Bookings Not Canceled",
         "Average ADR",
         "Hotel",
         "Is Repeated Customer?")

pvaltable = data.frame(Variables = vars, "P values" = pvals)
pvaltable$P.values = as.character(pvaltable$P.values)
to_print = pvaltable %>% 
  xtable(align="ccc", caption = "Table 3: P Values from 2-proportion Z Test")
print(to_print, 
      "html", 
      caption.placement = "top",
      scalebox = 0.7,
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
      )
```

### Model Selection: 

Using the significant variables, we created multiple predictive models: logistic, step-wise logistic, logistic with two-fold interaction, k-NN, and RandomForest. 

```{r, include=F}
#Data cleaning
library(MASS)
df_log = df %>%
  dplyr::select(hotel,
         is_canceled,
         lead_time,
         previous_cancellations,
         previous_bookings_not_canceled,
         adr,
         is_repeated_guest
         ) %>% mutate(id=row_number())

set.seed(216)
df_train=df_log %>% 
  sample_frac(0.80)
df_test=anti_join(df_log, df_train, by='id')
df_train= df_train %>%
  subset(select = -id)
df_test= df_test %>%
  subset(select= -id)
```

```{r, include=F}
#Model 1: Logistic
model1 = glm(
  is_canceled~., 
  family="binomial",
  data=df_train)

options("scipen"=100, "digits"=4)
summary(model1)

df_test = df_test %>% add_predictions(
  model1,
  var="predicted_canc1") %>%
  mutate(predicted_canc1 = ifelse(predicted_canc1 > 0.5,1,0))
```

#### Logistic Regression

To provide an example of one of our models, here is a table of coefficients for the simple logistic model:

```{r, results="asis", echo=F}
log_table = tidy(model1)[,c("term", "estimate", "p.value")] %>%
  rename(Term="term",
         Estimate="estimate",
         P.value="p.value") %>%
  mutate(Estimate=format(round(Estimate, 4), nsmall=4),
         P.value=formatC(P.value, format="e", digits = 3))

to_print_log_mod = log_table %>% 
  xtable(align="cccc", caption = "Table 4: Coefficients of Simple Logistic Model")
print(to_print_log_mod, 
      "html", 
      caption.placement = "top",
      scalebox = 0.7,
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F, eval=F}
#Model 2: Stepwise logistic
model2 = stepAIC(model1)

df_test = df_test %>% add_predictions(
  model2,
  var="predicted_canc2") %>%
  mutate(predicted_canc2 = ifelse(predicted_canc2 > 0.5,1,0))
```

```{r, include=F, eval=F}
#Model 3: Logistic with twofold interaction
model3 = glm(
  is_canceled~.^2, 
  family="binomial",
  data=df_train)
tidy(model3)[,c("term", "estimate", "p.value")] #make tables using these tibbles?

df_test = df_test %>% add_predictions(
  model3,
  var="predicted_canc3") %>%
  mutate(predicted_canc3 = ifelse(predicted_canc3 > 0.5,1,0))
```

```{r, echo=F}
#standardize dataset for k-NN and RandomForest
standardize = function(vector) {
  return(sd(vector)*vector + 
           mean(vector)
              )
}

#Sid's accuracy fxn
#accuracy = function(x) {
#  sum(diag(x)/(sum(rowSums(x)))) * 100
#}

#input df_test$predicted_canc1, or 2, etc.
sensitivity = function(predicted_canc) {
  return(
    sum(df_test$is_canceled & predicted_canc) /
      sum(df_test$is_canceled)
  )
}

specificity = function(predicted_canc) {
  return(
    sum(!df_test$is_canceled & predicted_canc==0) /
      sum(!df_test$is_canceled)
  )
}

accuracy = function(predicted_canc) {
  (
  sum(df_test$is_canceled & predicted_canc) + 
    sum(!df_test$is_canceled & predicted_canc==0)
  ) / nrow(df_test)
}
```


```{r, eval=T, include=F}
#Model4: k-NN, k=11

df_knn = df_test %>%
  mutate(
    previous_cancellations=standardize(previous_cancellations),
    previous_bookings_not_canceled=standardize(previous_bookings_not_canceled),
    hotel=ifelse(hotel=="Resort Hotel", 1, 0),
    hotel=standardize(hotel),
    lead_time=standardize(lead_time),
    adr=standardize(adr)
    ) %>% 
  mutate(predicted_canc4=knn(
    train=dplyr::select(
      df_train,
      lead_time,
      adr,
      previous_cancellations
      ),
    test=dplyr::select(
      df_test,
      lead_time,
      adr,
      previous_cancellations
    ),
    cl=
      factor(
      df_train$is_canceled,
      levels=c(0,1),
      labels=c("0","1")
    ),
    k=11)
  ) %>%
  dplyr::select(predicted_canc4)

df_test = bind_cols(df_test, df_knn) %>%
  mutate(predicted_canc4 = as.integer(predicted_canc4)-1)
```

```{r, eval=T, echo=F}
#RandomForest
rf = randomForest(is_canceled~.,
                  data = df_train,
                  ntree=30)
predicted = as.integer(predict(rf, newdata=df_test))-1
conf_mat = table(predicted, df_test$is_canceled)
df_test = df_test %>%
  mutate(predicted_canc5 = predicted)
```

#### K Nearest Neihbors (KNN)

**Choosing k for k-NN**

To determine which k value we should use for our k-NN model, we analyzed changes in accuracy, sensitivity, and specificity over time. In the context of our situation, it is more important that hotels correctly classify those who did not cancel, because we want to minimize the hassle from overbooking rooms that weren't actually canceled. However, we still want to maintain accuracy. Thus, we care more about accuracy and specificity than sensitivity. Accordingly, we chose k=11, because it maximizes accuracy$\times$specificity. Below is a visualization of this analysis.

```{r, echo=F, fig.width=6, fig.height=6}
k_df_plot = k_df %>% 
  rename(
    "Accuracy"="acc",
    "Sensitivity"="sens",
    "Specificity"="spec"
  ) %>%
  gather(
    "Accuracy":"Specificity", 
    key="Metric", 
    value="Value"
    )
ggplot(k_df_plot) + 
  geom_line(aes(x=k, y=Value, color=Metric)) + 
  ggtitle("Performance of k-NN model by k value") + 
  geom_vline(xintercept=11, color="black", size=0.5)
```

#### Random Forest

As for the RandomForest model, there was little variation of metrics by ntree value. Nevertheless, we chose parameter ntree=30 because it maximized accuracy$\times$specificity.

```{r, echo=F}
ggplot(rf_stats %>% rename(Metric=metric)) + 
  geom_line(aes(x=n, y=value, color=Metric)) + 
  geom_vline(xintercept=30, color="black", size=0.5) + 
  ggtitle("Performance of RandomForest Model by ntree Value") + 
  xlab("ntree") + 
  ylab("Value")
```


### Model Performance

The logistic models performed the same in terms of accuracy, sensitivity, and specificity, so we consider only the simple logistic model here. Our models are:

**Model 1:** Logistic

**Model 2:** k-NN, with k=11

**Model 3:** RandomForest, with ntree= 30

Below are metrics of our models' performance. 

```{r, results="asis", echo=F}

metrics_table = tribble(
  ~Model, ~Sensitivity, ~Specificity, ~Accuracy, ~Spec_Times_Accuracy,
  1, sensitivity(df_test$predicted_canc1), specificity(df_test$predicted_canc1), accuracy(df_test$predicted_canc1), specificity(df_test$predicted_canc1)*accuracy(df_test$predicted_canc1),
  2, k_df$sens[[11]], k_df$spec[[11]], k_df$acc[[11]], k_df$spec[[11]]*k_df$acc[[11]],
  3, 0.25, 0.99, 0.72, 0.71
) %>% mutate(Model=as.integer(Model))

to_print1 = metrics_table %>% 
  xtable(align="cccccc")
print(to_print1, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F}
detach("package:MASS", unload = TRUE)
```
