---
title: "HotelsFinalAnalysis"
author: "Walker Burgin, Tara Ghorpadkar, David Snider, Sid Vanam"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,include=F}
library(tidyverse)
library(countrycode)
library(rvest)
library(dplyr)
library(tidyr)
library(xtable)
library(modelr)
library(broom)
library(class)
library(lubridate)
library(pracma)
library(class)


df = read_csv("hotel_booking.csv")
k_df = read_csv("k_df.csv")
```

<center>

![Vila Vita Resort in Algarve, Portugal. Provided by The Leading Hotels of the World.](lw1306_82442005_720x450.jpg)

</center>

# Introduction

Our group used data describing hotel bookings from two hotels in Portugal to answer questions relevant to the travel industry. Firstly, we asked whether we could predict room rates with confidence. Such a tool would be useful for travel agencies, hotels and customers. Although hotels can provide rates only for a finite number of months, a model that predicts future rates may enable travel agencies to book vacations further into the future. Using such a model, travel agencies would provide more utility to both customers and hotels. Customers could have more booking options with greater certainty as to price, while hotels could increase ease of transaction. Hotels could also understand demand patterns earlier, and thus prepare their budget accordingly.

Secondly, we asked which model best predicts cancellation. In our dataset, about one third (0.37) of bookings ended up getting canceled. Hotels that can predict cancellation can modify operations accordingly. For example, when asking if a customer wishes to be put on a waitlist, the booker can inform them of the likelihood of a cancellation that could give them a room. Alternatively, a hotel could double book a proportion of rooms that are predicted to be canceled - a risk, but perhaps a profitable one. 

# Data

```{r, include=F}
#data cleaning
cleaned1 = df %>% 
  filter(is_canceled == 0) %>% 
  dplyr::select(
    hotel,
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month,
    stays_in_week_nights, 
    stays_in_weekend_nights, 
    adr) %>% 
  mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% 
  arrange(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month) %>%
  dplyr::select(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month, 
    length_of_stay, 
    adr, 
    hotel) 
cleaned1$arrival_date_month = as.integer(
  factor(cleaned1$arrival_date_month, 
         levels = month.name))
cleaned1 = cleaned1 %>%
  unite("arrival_date", 
        c("arrival_date_year", 
          "arrival_date_month", 
          "arrival_date_day_of_month"), 
        sep = "/") %>% 
  filter(adr != 0.00)

city_hotels2 = cleaned1 %>% 
  filter(hotel == "City Hotel")
resort_hotels2 = cleaned1 %>%
  filter(hotel == "Resort Hotel")

# city_hotels2 = city_hotels2 %>% 
#   dplyr::select(
#     arrival_date_year, 
#     arrival_date_month, 
#     arrival_date_day_of_month, 
#     length_of_stay, 
#     adr) %>% 
#   unite("arrival_date", 
#         c("arrival_date_year", 
#           "arrival_date_month", 
#           "arrival_date_day_of_month"), 
#         sep = "/") %>% 
#   filter(adr != 0.00)

city_hotels2$arrival_date <- as.Date(city_hotels2$arrival_date)
city_hotels2 = city_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )
resort_hotels2$arrival_date <- as.Date(resort_hotels2$arrival_date)
resort_hotels2 = resort_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )

model_data_city = city_hotels2
start_date = as.Date("2015-07-01")
model_data_city$arrival_date <- as.numeric(
  difftime(model_data_city$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.city <- model_data_city$arrival_date

model_data_resort = resort_hotels2
model_data_resort$arrival_date <- as.numeric(
  difftime(model_data_resort$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.resort <- model_data_resort$arrival_date
```

The dataset contains 119,319 bookings for two hotels located in Portugal over about 2 years. There are 32 variables included in the data set; our research questions concerned a select few. Our first question uses "arrival_date" to predict the variable "avg_adr". Our group combined the given variables arrival_date_year, arrival_date_month, and arrival_date_day_of_month into the variable arrival_date, which records the client's date of arrival in days since the earliest arrival date in the dataset: July 1, 2015. To do so, we converted each arrival date into a Date type, and used a function to obtain days elapsed. We created the variable "avg_adr" using the variable "adr". ADR is defined as the client's total transaction costs divided by their staying days. In creating "avg_adr", we calculated the mean ADR value for one day for each hotel. Doing so facilitated easy observation of the oscillating relationship between avg_adr and arrival_date, which provided the motivation for our first question. 

Data table for Q1: 

```{r, echo=F, results="asis"}
#Table for Q1
q1table = model_data_city %>% 
  head(4) %>%
  mutate(arrival_date = as.integer(arrival_date)) %>%
  xtable(
    align=c("c","c","c"),
    type="html")
print(q1table, 
      "html", 
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")

```

Our second question predicts the variable "is_canceled", which has a value of 1 if the booking was canceled, and 0 otherwise. Analysis revealed that certain variables had a statistically significant relationship with is_canceled. The following are the variables we analyzed. "Hotel" describes whether the observation was at the city hotel or the resort hotel. "is_repeated_guest" is a binary variable, valued at 1 if the guest has booked previously. "lead_time" describes the number of days between entrance into the booking system and the customer's arrival. "previous_bookings_not_canceled" describes the number of the client's previous bookings that were not canceled, while "previous_cancellations" describes those that were canceled.

Data Table for Q2:

```{r, results="asis", echo=F}
q2table = (df %>% select(
  is_canceled,
  hotel,
  is_repeated_guest,
  adr,
  lead_time,
  previous_bookings_not_canceled,
  previous_cancellations
  ) %>% 
  filter(adr!= 0))[3:7,] %>%
  mutate(
    is_canceled=as.integer(is_canceled),
    is_repeated_guest=as.integer(is_repeated_guest),
    lead_time=as.integer(lead_time),
    previous_bookings_not_canceled = as.integer(previous_bookings_not_canceled),
    previous_cancellations = as.integer(previous_cancellations)
  ) %>%
  xtable(
    align="cccccccc", 
    type="html"
    )
print(q2table,
      "html",
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")
```

# Results

## Question 1: Can we predict future room rates with confidence?

```{r, echo=F, fig.align="center", fig.width=6, fig.height=6, fig.cap="Figure 1:" }
xc <- cos(2*pi*model_data_city$arrival_date/365.25)
xs <- sin(2*pi*model_data_city$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_city)
model_data_city$pred1 <- predict(fit.lm, model_data_city)
model.func = function(day){
  return(
    fit.lm$coefficients[[1]] + fit.lm$coefficients[[2]]*cos(2*pi*day/365.25) + fit.lm$coefficients[[3]]*sin(2*pi*day/365.25) + fit.lm$coefficients[[4]]*day
  )
}
p1 <- ggplot() + 
  geom_point(data = model_data_city, aes(x = arrival_date, y = avg_adr)) + 
  geom_hline(aes(yintercept=0))
p1.trend = p1  + 
  geom_line(data = model_data_city, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_city = bind_rows(model_data_city, new)
model_data_city$pred <- model.func(model_data_city$arrival_date)
p1.trend + 
  geom_line(data = model_data_city, 
            aes(x = arrival_date, 
                y = pred)) + geom_vline(xintercept = 365) + geom_vline(xintercept = 730) + geom_vline(xintercept = 1095) + xlab("Days elapsed since July 1, 2015") + ylab("Average Daily Rate") + ggtitle("City Hotel Predictions")
```

```{r, echo=F}
xc <- cos(2*pi*model_data_resort$arrival_date/365.25)
xs <- sin(2*pi*model_data_resort$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_resort)
model_data_resort$pred1 <- predict(fit.lm, model_data_resort)
p2 <- ggplot() + geom_point(data =model_data_resort, aes(x = arrival_date, y = avg_adr)) + geom_hline(aes(yintercept=0))
p2.trend = p2  + 
  geom_line(data = model_data_resort, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_resort = bind_rows(model_data_resort, new)
model_data_resort$pred <- model.func(model_data_resort$arrival_date)
p2.trend + geom_line(data = model_data_resort, aes(x = arrival_date, y = pred)) +  + geom_vline(xintercept = 365) + geom_vline(xintercept = 730) + geom_vline(xintercept = 1095) + xlab("Days elapsed since July 1, 2015") + ylab("Average Daily Rate") + ggtitle("Resort Hotel Predictions")
```



```{r, echo=F, message=F}
#Walker's
h <- read.csv("hotel_booking.csv")
h2 = h %>% 
  select(hotel, 
         arrival_date_month, 
         arrival_date_day_of_month, 
         arrival_date_year, 
         country,
         adr, 
         is_canceled) %>% 
  rename(tp = hotel, 
         ogn = country, 
         aM = arrival_date_month, 
         aD = arrival_date_day_of_month, 
         aY = arrival_date_year, 
         adr = adr)
month_levels <- c("January", "February", "March", "April", 
                  "May", "June", "July", "August", 
                  "September", "October", "November", "December")
repeat_levels <- c(0, 1)
h2$aM =  factor(h2$aM,levels = month_levels)
ct_h = h2 %>% 
  filter(tp == "City Hotel", is_canceled == 0) %>% 
  filter(ogn != "NULL")
rst_h = h2 %>% 
  filter(tp == "Resort Hotel", is_canceled == 0) %>% 
  filter(ogn != "NULL")
ct_h_freq = ct_h%>% 
  filter(adr != 0.00)%>% 
  group_by(ogn, aM) %>% 
  summarise(n = n()) %>% 
  mutate(frequency = n/sum(n))
rst_h_freq = rst_h %>% 
  filter(adr != 0.00)%>% 
  group_by(ogn, aM) %>% 
  summarise(n = n()) %>% 
  mutate(frequency = n/sum(n))
ct_h_adr = ct_h %>% 
  group_by(ogn, aM) %>% 
  arrange(ogn, aM) %>% 
  summarize_at(vars(adr),funs(mean(.,na.rm = TRUE) )) %>% 
  rename(amr = adr) 
rst_h_adr = rst_h %>% 
  group_by(ogn, aM) %>% 
  arrange(ogn, aM) %>% 
  summarize_at(vars(adr), funs(mean(., na.rm = TRUE) )) %>% 
  rename(amr = adr) 
ct_h_top = ct_h %>% 
  group_by(ogn) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
ct_h_join = inner_join(ct_h_adr, ct_h_top, by = "ogn")
rst_h_top = rst_h %>% 
  group_by(ogn) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
rst_h_join = inner_join(rst_h_adr, rst_h_top, by = "ogn")
ct_h_freq = ct_h_freq %>% 
  filter(n > 80, frequency < 0.6)

h2 = h %>% 
  filter(hotel == "City Hotel", is_canceled == 0) %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month,stays_in_week_nights, stays_in_weekend_nights, adr) %>% mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% arrange(arrival_date_year, arrival_date_month, arrival_date_day_of_month)

h2$arrival_date_month = as.integer(factor(h2$arrival_date_month, levels = month.name))

h2 = h2 %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month, length_of_stay, adr) %>% unite("arrival_date", c("arrival_date_year", "arrival_date_month", "arrival_date_day_of_month"), sep = "/") %>% filter(adr != 0.00)

h2$arrival_date <- as.Date(h2$arrival_date)
h2 = h2 %>% arrange(arrival_date)  %>% group_by(arrival_date) %>% summarise(avg_length_of_stay = mean(length_of_stay), avg_adr = mean(adr))

mod = h2
start_date = as.Date("2015-07-01")
mod$arrival_date <- as.numeric(difftime(mod$arrival_date, start_date, unit = "days"))
NumDays.city <- mod$arrival_date
xc <- cos(2*pi*NumDays.city/365.25)
xs <- sin(2*pi*NumDays.city/365.25)  
fit.lm <- lm(avg_adr ~ xc + xs + mod$arrival_date, data = mod)
model.func = function(day) {
  return(
    fit.lm$coefficients[[1]] + 
    fit.lm$coefficients[[2]]*cos(2*pi*day/365.25) + 
    fit.lm$coefficients[[3]]*sin(2*pi*day/365.25) + 
    fit.lm$coefficients[[4]]*day
  )
}
new = data.frame(arrival_date=793:1577)
mod = bind_rows(mod,new)
mod$pred <- model.func(mod$arrival_date)
mod$residual <- mod$avg_adr-mod$pred


resid <- remove_missing(mod,na.rm=TRUE,vars = names(mod))
resid$r2 <- resid$residual^2
RMSError <- sqrt(mean(resid$r2))
f_density<- function(x){
  (1+(x/1577))^2
}

ggplot()+
  geom_errorbar(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred,
      ymax=mod$pred+(f_density(mod$arrival_date)*RMSError),
      ymin=mod$pred-(f_density(mod$arrival_date)*RMSError)),
    alpha=.025,
    color="red")+
  geom_point(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$avg_adr),
    size=1,
    color="red",
    alpha=.25)+
  xlab("Time Elapsed Since 1 July 2015 (days)")+
  ylab("Average Adr")+
  theme_classic()+
  ggtitle("Forecasted Average ADR")+
  geom_vline(xintercept = 793,linetype=1,alpha=.05)+
  geom_line(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred),
    color="purple",
    size=.5)+
  geom_smooth(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred+(2*f_density(mod$arrival_date)*RMSError)),
      xseq=793:1577,
      se=FALSE,
      color="red",
      alpha=.25,
      linetype=1,
      size=.5
    )+
  geom_smooth(
    mapping=aes(
      x=mod$arrival_date,
      y=mod$pred-(2*f_density(mod$arrival_date)*RMSError)),
      xseq=793:1577,
      se=FALSE,
      color="red",
      alpha=.25,
      linetype=1,
    size=.5
    )+
  geom_vline(xintercept=365.25/2,color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(3/2),color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(5/2),color="red",linetype=3,size=.5)+
  geom_vline(xintercept=365.25*(7/2),color="red",linetype=3,size=.5)
ggplot()+theme_classic()+ggtitle("Accuracy of Predicted Curve")+ylab("Average ADR")+xlab("Arrival Date")+geom_area(mapping=aes(x=resid$arrival_date,y=resid$residual),fill="red")+geom_hline(yintercept = RMSError,linetype=2)
```
Our prediction model is displayed in "Forecasted Average ADR", with confidence intervals defined by the RMS Error of 13.31. Our second chart, "Accuracy of Predicted Curve", identifies which segments of the prediction model are less accurate than others at mapping the dataset.

## Question 2: Which model best predicts cancellation?

### Analysis of significant variables:

To determine which variables we should use in our models, we started by identifying the variables that had a significant relationship with cancellation. Here are graphs showing the significant variables' relationship with cancellation: 

```{r, echo=F, figures-side, fig.show="hold", out.width="50%"}
leadgraph = df %>% 
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_lead_time = mean(lead_time)) %>% 
  ungroup() %>%
  rename(value=avg_lead_time)
leadgraph$key=rep("Lead Time", 2)

prevgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_canc = mean(previous_cancellations)) %>% 
  ungroup() %>%
  rename(value=avg_prev_canc)
prevgraph$key=rep("Previous Cancellations", 2)

prevuncancgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_uncanc = mean(previous_bookings_not_canceled)) %>% 
  ungroup() %>%
  rename(value=avg_prev_uncanc)
prevuncancgraph$key=rep("Previous Bookings Not Canceled", 2)

adrgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_adr = mean(adr)) %>% 
  ungroup() %>%
  rename(value=avg_adr)
adrgraph$key=rep("ADR", 2)

fullgraph = bind_rows(leadgraph, prevgraph, prevuncancgraph, adrgraph)

ggplot(fullgraph, aes(x=`as.logical(is_canceled)`, y=value)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales = "free") + 
  xlab("Is Canceled?") + 
  ylab("Mean Value")
  
hotelgraph = df %>%
  group_by(hotel) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=hotel)
hotelgraph$key=rep("Hotel", 2)

repeatgraph = df %>%
  group_by(as.logical(is_repeated_guest)) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=`as.logical(is_repeated_guest)`)
repeatgraph$key=rep("Is Repeated Guest?", 2)
repeatgraph$value=as.character(repeatgraph$value)

fullgraph2 = bind_rows(hotelgraph, repeatgraph)

ggplot(fullgraph2, aes(x=value, y=prop_canceled)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales="free") + 
  xlab("Value") + 
  ylab("Proportion Canceled")
```

Below are the P values for the above relationships. The P values for the first 4 variables were calculated using a T-test. The P values for the last 2 were calculated using a two proportion Z-test.

```{r, results="asis", echo=F}
pvals = c()

pvals = c(
  t.test(df$lead_time~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_cancellations~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_bookings_not_canceled~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$adr~as.logical(df$is_canceled))$p.value[[1]],
  (prop.test(x=hotelgraph$num_canceled, 
             n=hotelgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]],
  (prop.test(x=repeatgraph$num_canceled, 
             n=repeatgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]]
)
pvals=formatC(x=pvals, format="e", digits=2)

vars = c("Average Lead Time",
         "Average Previous Cancellations",
         "Average Previous Bookings Not Canceled",
         "Average ADR",
         "Hotel",
         "Is Repeated Customer?")

pvaltable = data.frame(Variables = vars, "P values" = pvals)
pvaltable$P.values = as.character(pvaltable$P.values)
to_print = pvaltable %>% 
  xtable(align="ccc")
print(to_print, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
      )
```

### Model Selection: 

Using the significant variables, we created multiple predictive models: logistic, step-wise logistic, logistic with two-fold interaction, k-NN, and RandomForest. 

```{r, include=F}
#Data cleaning
library(MASS)
df_log = df %>%
  dplyr::select(hotel,
         is_canceled,
         lead_time,
         previous_cancellations,
         previous_bookings_not_canceled,
         adr,
         is_repeated_guest
         ) %>% mutate(id=row_number())

set.seed(216)
df_train=df_log %>% 
  sample_frac(0.80)
df_test=anti_join(df_log, df_train, by='id')
df_train= df_train %>%
  subset(select = -id)
df_test= df_test %>%
  subset(select= -id)
```

```{r, include=F}
#Model 1: Logistic
model1 = glm(
  is_canceled~., 
  family="binomial",
  data=df_train)

options("scipen"=100, "digits"=4)
summary(model1)

df_test = df_test %>% add_predictions(
  model1,
  var="predicted_canc1") %>%
  mutate(predicted_canc1 = ifelse(predicted_canc1 > 0.5,1,0))
```

To provide an example of one of our models, here is a table of coefficients for the simple logistic model:

```{r, results="asis", echo=F}
log_table = tidy(model1)[,c("term", "estimate", "p.value")] %>%
  rename(Term="term",
         Estimate="estimate",
         P.value="p.value") %>%
  mutate(Estimate=format(round(Estimate, 4), nsmall=4),
         P.value=formatC(P.value, format="e", digits = 3))

to_print_log_mod = log_table %>% 
  xtable(align="cccc")
print(to_print_log_mod, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F, eval=F}
#Model 2: Stepwise logistic
model2 = stepAIC(model1)

df_test = df_test %>% add_predictions(
  model2,
  var="predicted_canc2") %>%
  mutate(predicted_canc2 = ifelse(predicted_canc2 > 0.5,1,0))
```

```{r, include=F, eval=F}
#Model 3: Logistic with twofold interaction
model3 = glm(
  is_canceled~.^2, 
  family="binomial",
  data=df_train)
tidy(model3)[,c("term", "estimate", "p.value")] #make tables using these tibbles?

df_test = df_test %>% add_predictions(
  model3,
  var="predicted_canc3") %>%
  mutate(predicted_canc3 = ifelse(predicted_canc3 > 0.5,1,0))
```

```{r, echo=F}
#standardize dataset for k-NN and RandomForest
standardize = function(vector) {
  return(sd(vector)*vector + 
           mean(vector)
              )
}

#Sid's accuracy fxn
accuracy = function(x) {
  sum(diag(x)/(sum(rowSums(x)))) * 100
}
```


```{r, eval=T, include=F}
#Model4: k-NN, k=11

df_knn = df_test %>%
  mutate(
    previous_cancellations=standardize(previous_cancellations),
    previous_bookings_not_canceled=standardize(previous_bookings_not_canceled),
    hotel=ifelse(hotel=="Resort Hotel", 1, 0),
    hotel=standardize(hotel),
    lead_time=standardize(lead_time),
    adr=standardize(adr)
    ) %>% 
  mutate(predicted_canc4=knn(
    train=dplyr::select(
      df_train,
      lead_time,
      adr,
      previous_cancellations
      ),
    test=dplyr::select(
      df_test,
      lead_time,
      adr,
      previous_cancellations
    ),
    cl=
      factor(
      df_train$is_canceled,
      levels=c(0,1),
      labels=c("0","1")
    ),
    k=11)
  ) %>%
  dplyr::select(predicted_canc4)

df_test = bind_cols(df_test, df_knn) %>%
  mutate(predicted_canc4 = as.integer(predicted_canc4)-1)
```

```{r, eval=F, echo=F}
library(randomForest)
#RandomForest
set.seed(216)
ran = sample(1:nrow(df), 0.8 * nrow(df))

df_hotel_binary = df %>% 
  mutate(hotel = ifelse(hotel == "Resort Hotel", 1, 0))
df_norm = as.data.frame(lapply(df_hotel_binary[, c("previous_cancellations", "previous_bookings_not_canceled", "lead_time", "adr", "hotel")], standardize)) 

#subset = df[sample(x=nrow(df), size=10000), ]

#df_target_category = df[ran, "is_canceled"] %>% pull(is_canceled)
#df_test_category = df[-ran, "is_canceled"] %>% pull(is_canceled)
df_train$is_canceled = df_train$is_canceled %>% as.factor()

rf = randomForest(is_canceled~ previous_cancellations+previous_bookings_not_canceled+lead_time+adr+hotel,
                  data = df_train,
                  ntree=100)
print(rf)
```

**Choosing k for k-NN**

To determine which k value we should use for our k-NN model, we analyzed changes in accuracy, sensitivity, and specificity over time. In the context of our situation, it is more important that hotels correctly classify those who did not cancel, because we want to minimize the hassle from overbooking rooms that weren't actually canceled. However, we still want to maintain accuracy. Thus, we care more about accuracy and specificity than sensitivity. Accordingly, we chose k=11, because it maximizes accuracy$\times$specificity. Below is a visualization of this analysis.

```{r, echo=F}
k_df_plot = k_df %>% 
  rename(
    "Accuracy"="acc",
    "Sensitivity"="sens",
    "Specificity"="spec"
  ) %>%
  gather(
    "Accuracy":"Specificity", 
    key="Metric", 
    value="Value"
    )
ggplot(k_df_plot) + 
  geom_line(aes(x=k, y=Value, color=Metric)) + 
  ggtitle("Performance of k-NN model by k value") + 
  geom_vline(xintercept=11, color="black", size=0.5)
```

### Model Performance

The logistic models performed the same in terms of accuracy, sensitivity, and specificity, so we consider only the simple logistic model here. Our models are:

**Model 1:** Logistic

**Model 2:** k-NN, with k=11

**Model 3:** RandomForest, with ntree=**fill in this blank**

Below are metrics of our models' performance. 

```{r, results="asis", echo=F}
#input df_test$predicted_canc1, or 2, etc.
sensitivity = function(predicted_canc) {
  return(
    sum(df_test$is_canceled & predicted_canc) /
      sum(df_test$is_canceled)
  )
}

specificity = function(predicted_canc) {
  return(
    sum(!df_test$is_canceled & !predicted_canc) /
      sum(!df_test$is_canceled)
  )
}

accuracy = function(predicted_canc) {
  (
  sum(df_test$is_canceled & predicted_canc) + 
    sum(!df_test$is_canceled & !predicted_canc)
  ) / nrow(df_test)
}

metrics_table = tribble(
  ~Model, ~Sensitivity, ~Specificity, ~Accuracy,
  1, sensitivity(df_test$predicted_canc1), specificity(df_test$predicted_canc1), accuracy(df_test$predicted_canc1),
  2, k_df$sens[[11]], k_df$spec[[11]], k_df$acc[[11]]
) %>% mutate(Model=as.integer(Model))

to_print1 = metrics_table %>% 
  xtable(align="ccccc")
print(to_print1, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F}
detach("package:MASS", unload = TRUE)
```

```{r, include=F}
standardize = function(vector) {
  z = (vector-mean(vector))/sd(vector)
  return(z)
}

#divides correct prediction by total predictions
accuracy = function(x) {
  sum(diag(x)/(sum(rowSums(x))))
}
```

```{r, eval=F, include=F}
#Created k_df file, so we no longer need to run this code. Storing it here with eval=F.
set.seed(216)
ran = sample(1:nrow(df), 0.8 * nrow(df))
df_hotel_binary = df %>% mutate(hotel = ifelse(hotel == "Resort Hotel", 1, 0))
df_norm = as.data.frame(lapply(df_hotel_binary[, c("previous_cancellations", "previous_bookings_not_canceled", "lead_time", "adr", "hotel")], standardize)) 
#subset = df[sample(x=nrow(df), size=10000), ]
df_train = df_norm[ran, ] #%>% cbind(., )
df_test = df_norm[-ran, ]
df_target_category = df[ran, "is_canceled"] %>% pull(is_canceled)
df_test_category = df[-ran, "is_canceled"] %>% pull(is_canceled)
acc = vector("double", 100)
sens = vector("double", 100)
spec = vector("double", 100)
options(width = 80)
for (k in 1:100){
  knn_output = knn(df_train, df_test, cl=df_target_category, k=k)
  confusion_matrix = table(knn_output, df_test_category)
  acc[[k]]= accuracy(confusion_matrix)
  sens[[k]]= confusion_matrix[2,2] / sum(confusion_matrix[,2])
  spec[[k]]= confusion_matrix[1,1] / sum(confusion_matrix[,1])
}
k = as.integer(1:100)
k_df = data.frame(
  k,
  acc,
  sens,
  spec
)
```

# Next Steps:

-Incorporate RF model into ModelPerformance, and Model selection?

- ?Calculate F1 score for both Logistic Regression and KNN + Visualize

- Make a RF model w/ accomopanying metrics
